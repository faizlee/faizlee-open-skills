#!/usr/bin/env python3
"""
é¡¹ç›®çŸ¥è¯†ç´¢å¼• - æ„å»ºç´¢å¼•è„šæœ¬

æ‰«æ docs/ ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡æ¡£ï¼Œæå–å…³é”®è¯å’Œå…ƒæ•°æ®ï¼Œ
ç”Ÿæˆç»“æ„åŒ–ç´¢å¼• (INDEX.md) å’Œé—®é¢˜è®°å½• (problem-log.json)
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any


class IndexBuilder:
    def __init__(self, project_root: str = ".", docs_dir: str = "docs"):
        self.project_root = Path(project_root).resolve()
        self.docs_dir = self.project_root / docs_dir
        self.index_dir = self.docs_dir / "knowledge-index"
        self.documents = []
        self.problems = []

    def detect_project_root(self) -> Path:
        """æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•"""
        current = Path.cwd()
        while current != current.parent:
            if (current / ".git").exists() or (current / "package.json").exists():
                return current
            current = current.parent
        return Path.cwd()

    def scan_documents(self) -> List[Path]:
        """æ‰«ææ‰€æœ‰ Markdown æ–‡æ¡£"""
        print(f"ğŸ” æ‰«ææ–‡æ¡£ç›®å½•: {self.docs_dir}")
        md_files = list(self.docs_dir.glob("**/*.md"))
        print(f"âœ… æ‰¾åˆ° {len(md_files)} ä¸ªæ–‡æ¡£")
        return md_files

    def extract_metadata(self, file_path: Path) -> Dict[str, Any]:
        """ä»æ–‡æ¡£ä¸­æå–å…ƒæ•°æ®"""

        # è¯»å–æ–‡æ¡£å†…å®¹
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€ä¸ª # æ ‡é¢˜ï¼‰
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        title = title_match.group(1) if title_match else file_path.stem

        # æå–å…³é”®è¯ï¼ˆä»æ ‡é¢˜å’Œå†…å®¹ä¸­ï¼‰
        keywords = self.extract_keywords(content, title)

        # æ£€æµ‹æ¨¡å—ï¼ˆåŸºäºæ–‡ä»¶è·¯å¾„å’Œå†…å®¹ï¼‰
        module = self.detect_module(file_path, content)

        # æ£€æµ‹ç±»å‹ï¼ˆåŸºäºæ–‡ä»¶åï¼‰
        doc_type = self.detect_type(file_path)

        # æå–ç›¸å…³æ–‡æ¡£
        related = self.extract_related_documents(content)

        return {
            "file": str(file_path.relative_to(self.project_root)),
            "title": title,
            "keywords": keywords,
            "module": module,
            "type": doc_type,
            "related_documents": related,
            "quality": "medium",  # é»˜è®¤è´¨é‡
            "status": "active",
            "created_date": datetime.fromtimestamp(file_path.stat().st_ctime).isoformat(),
            "last_updated": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
            "reference_count": 0,
            "weight": 50
        }

    def extract_keywords(self, content: str, title: str) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = set()

        # ä»æ ‡é¢˜æå–
        title_words = re.findall(r'[\w\u4e00-\u9fff]+', title)
        keywords.update(title_words[:5])

        # ä» H2ã€H3 æ ‡é¢˜æå–
        headings = re.findall(r'^#{2,3}\s+(.+)$', content, re.MULTILINE)
        for heading in headings:
            words = re.findall(r'[\w\u4e00-\u9fff]+', heading)
            keywords.update(words[:3])

        # ä»æ–‡ä»¶å†…å®¹æå–é«˜é¢‘è¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
        # TODO: å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ NLP ç®—æ³•

        return list(keywords)[:10]

    def detect_module(self, file_path: Path, content: str) -> str:
        """æ£€æµ‹æ–‡æ¡£æ‰€å±æ¨¡å—"""
        path_str = str(file_path).lower()

        # åŸºäºæ–‡ä»¶è·¯å¾„åˆ¤æ–­
        if "xiaohongshu" in path_str or "cover" in path_str:
            return "xiaohongshu-cover"
        elif "video" in path_str or "generator" in path_str:
            return "video-generator"
        elif "auth" in path_str:
            return "auth"
        elif "test" in path_str:
            return "testing"
        elif "refactor" in path_str:
            return "refactor"
        elif "thumbnail" in path_str:
            return "thumbnail"
        elif "progress" in path_str:
            return "progress-display"
        else:
            return "general"

    def detect_type(self, file_path: Path) -> str:
        """æ£€æµ‹æ–‡æ¡£ç±»å‹"""
        name = file_path.name.lower()

        if "bug" in name or "fix" in name or "error" in name:
            return "bug"
        elif "test" in name:
            return "test"
        elif "refactor" in name:
            return "refactor"
        elif "guide" in name or "tutorial" in name:
            return "guide"
        elif "report" in name:
            return "report"
        elif "implementation" in name:
            return "implementation"
        elif "design" in name:
            return "design"
        else:
            return "general"

    def extract_related_documents(self, content: str) -> List[str]:
        """æå–ç›¸å…³æ–‡æ¡£"""
        related = []

        # æŸ¥æ‰¾ Markdown é“¾æ¥
        links = re.findall(r'\[([^\]]+)\]\(([^)]+\.md)\)', content)
        for text, url in links:
            # æ¸…ç† URLï¼ˆå»é™¤ ../ ç­‰ï¼‰
            clean_url = url.lstrip('../')
            related.append(clean_url)

        return list(set(related))[:5]

    def build_index(self):
        """æ„å»ºç´¢å¼•"""
        print("\nğŸ—ï¸  å¼€å§‹æ„å»ºç´¢å¼•...")

        # æ‰«ææ–‡æ¡£
        md_files = self.scan_documents()

        # æå–å…ƒæ•°æ®
        print("\nğŸ“„ æå–æ–‡æ¡£å…ƒæ•°æ®...")
        for md_file in md_files:
            try:
                metadata = self.extract_metadata(md_file)
                self.documents.append(metadata)
                print(f"  âœ“ {metadata['file']}")
            except Exception as e:
                print(f"  âœ— {md_file}: {e}")

        # æŒ‰æ¨¡å—åˆ†ç±»
        print("\nğŸ“‚ æŒ‰æ¨¡å—åˆ†ç±»...")
        modules = {}
        for doc in self.documents:
            module = doc['module']
            if module not in modules:
                modules[module] = []
            modules[module].append(doc)

        # ç”Ÿæˆ INDEX.md
        print("\nğŸ“ ç”Ÿæˆ INDEX.md...")
        self.generate_index_md(modules)

        # ç”Ÿæˆ problem-log.json
        print("\nğŸ“ ç”Ÿæˆ problem-log.json...")
        self.generate_problem_log()

        print("\nâœ… ç´¢å¼•æ„å»ºå®Œæˆï¼")
        print(f"   - æ–‡æ¡£æ€»æ•°: {len(self.documents)}")
        print(f"   - æ¨¡å—æ•°é‡: {len(modules)}")
        print(f"   - ç´¢å¼•ä½ç½®: {self.index_dir}")

    def generate_index_md(self, modules: Dict[str, List[Dict]]):
        """ç”Ÿæˆ INDEX.md"""
        self.index_dir.mkdir(parents=True, exist_ok=True)
        index_file = self.index_dir / "INDEX.md"

        with open(index_file, 'w', encoding='utf-8') as f:
            f.write("# é¡¹ç›®çŸ¥è¯†ç´¢å¼•\n\n")
            f.write(f"> æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"> æ€»æ–‡æ¡£æ•°: {len(self.documents)}\n")
            f.write(f"> æ¨¡å—æ•°é‡: {len(modules)}\n\n")
            f.write("---\n\n")

            # æŒ‰æ¨¡å—ç”Ÿæˆç´¢å¼•
            for module_name, docs in sorted(modules.items()):
                f.write(f"## {module_name}\n\n")

                for doc in sorted(docs, key=lambda x: x['weight'], reverse=True):
                    f.write(f"### {doc['title']}\n\n")
                    f.write(f"- **æ–‡ä»¶**: `{doc['file']}`\n")
                    f.write(f"- **å…³é”®è¯**: {', '.join(doc['keywords'][:10])}\n")
                    f.write(f"- **ç±»å‹**: {doc['type']}\n")
                    f.write(f"- **æ¨¡å—**: {doc['module']}\n")
                    f.write(f"- **æƒé‡**: {doc['weight']}\n")
                    f.write(f"- **æœ€åå¼•ç”¨**: {doc['last_updated']}\n")

                    if doc['related_documents']:
                        f.write(f"- **ç›¸å…³æ–‡æ¡£**: {', '.join(doc['related_documents'][:5])}\n")

                    f.write("\n")

        print(f"âœ“ ç´¢å¼•å·²ä¿å­˜åˆ°: {index_file}")

    def generate_problem_log(self):
        """ç”Ÿæˆ problem-log.json"""
        problem_file = self.index_dir / "problem-log.json"

        data = {
            "version": "1.0",
            "last_updated": datetime.now().isoformat(),
            "problems": [],  # åˆå§‹ä¸ºç©ºï¼Œéšç€ä½¿ç”¨é€æ¸å¡«å……
            "frequent_problems": []
        }

        with open(problem_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ“ é—®é¢˜è®°å½•å·²ä¿å­˜åˆ°: {problem_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="æ„å»ºé¡¹ç›®çŸ¥è¯†ç´¢å¼•")
    parser.add_argument("--project-root", default=".", help="é¡¹ç›®æ ¹ç›®å½•")
    parser.add_argument("--docs-dir", default="docs", help="æ–‡æ¡£ç›®å½•")
    parser.add_argument("--auto-classify", action="store_true", help="è‡ªåŠ¨åˆ†ç±»æ¨¡å—")
    parser.add_argument("--extract-keywords", action="store_true", help="è‡ªåŠ¨æå–å…³é”®è¯")

    args = parser.parse_args()

    builder = IndexBuilder(args.project_root, args.docs_dir)
    builder.build_index()


if __name__ == "__main__":
    main()
