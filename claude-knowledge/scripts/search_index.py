#!/usr/bin/env python3
"""
é¡¹ç›®çŸ¥è¯†ç´¢å¼• - æœç´¢è„šæœ¬

åœ¨ç´¢å¼•ä¸­æœç´¢ç›¸å…³æ–‡æ¡£å’Œè§£å†³æ–¹æ¡ˆ
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime


class IndexSearcher:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.index_dir = self.project_root / "docs" / "knowledge-index"
        self.index_file = self.index_dir / "INDEX.md"
        self.problem_log = self.index_dir / "problem-log.json"

    def search(self, query: str, context: Dict = None) -> Dict[str, Any]:
        """æ‰§è¡Œæœç´¢ï¼ˆå¤åˆæ¨¡å¼ï¼‰"""

        print(f"ğŸ” æœç´¢æŸ¥è¯¢: {query}")

        results = {
            "query": query,
            "found": False,
            "results": [],
            "warnings": []
        }

        # æ¨¡å¼ 1: é—®é¢˜è®°å½•åŒ¹é…
        problem_results = self.search_problem_log(query)
        if problem_results:
            results["results"].extend(problem_results)
            print(f"  âœ“ é—®é¢˜è®°å½•åŒ¹é…: {len(problem_results)} ä¸ª")

        # æ¨¡å¼ 2: å…³é”®è¯æœç´¢
        keywords = self.extract_keywords(query)
        keyword_results = self.search_by_keywords(keywords)
        if keyword_results:
            results["results"].extend(keyword_results)
            print(f"  âœ“ å…³é”®è¯åŒ¹é…: {len(keyword_results)} ä¸ª")

        # æ¨¡å¼ 3: æ¨¡å—åˆ†ç±»æœç´¢
        module = self.detect_module(query)
        if module:
            module_results = self.search_by_module(module)
            if module_results:
                results["results"].extend(module_results)
                print(f"  âœ“ æ¨¡å—åŒ¹é…: {len(module_results)} ä¸ª")

        # æ¨¡å¼ 4: ç±»å‹æœç´¢
        doc_type = self.detect_type(query)
        if doc_type:
            type_results = self.search_by_type(doc_type)
            if type_results:
                results["results"].extend(type_results)
                print(f"  âœ“ ç±»å‹åŒ¹é…: {len(type_results)} ä¸ª")

        # å»é‡
        results["results"] = self.deduplicate(results["results"])

        # æ’åº
        results["results"] = self.rank_results(results["results"], query)

        # æ£€æŸ¥è´¨é‡
        for result in results["results"]:
            warnings = self.check_quality(result)
            if warnings:
                result["warnings"] = warnings
                results["warnings"].extend(warnings)

        results["found"] = len(results["results"]) > 0

        return results

    def search_problem_log(self, query: str) -> List[Dict]:
        """æ¨¡å¼ 1: é—®é¢˜è®°å½•åŒ¹é…"""
        if not self.problem_log.exists():
            return []

        with open(self.problem_log, 'r', encoding='utf-8') as f:
            data = json.load(f)

        results = []
        query_lower = query.lower()

        for problem in data.get("problems", []):
            # å®Œå…¨åŒ¹é…
            if query_lower in problem["question"].lower():
                for solution in problem["solutions"]:
                    results.append({
                        "type": "exact_match",
                        "problem": problem["question"],
                        "occurrence_count": problem["occurrence_count"],
                        "document": solution["document"],
                        "section": solution.get("section", ""),
                        "confidence": solution.get("confidence", "medium"),
                        "source": "problem-log"
                    })

        return results

    def search_by_keywords(self, keywords: List[str]) -> List[Dict]:
        """æ¨¡å¼ 2: å…³é”®è¯æœç´¢"""
        if not self.index_file.exists():
            return []

        results = []
        content = self.index_file.read_text(encoding='utf-8')

        # è§£æ INDEX.mdï¼ˆç®€åŒ–ç‰ˆï¼‰
        # å®é™…åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„è§£æå™¨

        current_doc = None
        for line in content.split('\n'):
            # æ£€æµ‹æ–‡æ¡£æ ‡é¢˜
            if line.startswith('### '):
                if current_doc and any(kw in current_doc.get('keywords', '').lower() for kw in keywords):
                    results.append(current_doc)
                current_doc = None

            # æå–å…ƒæ•°æ®
            elif line.startswith('- **æ–‡ä»¶**:'):
                current_doc = {"file": line.split('`')[1]}
            elif line.startswith('- **å…³é”®è¯**:') and current_doc:
                current_doc["keywords"] = line.split(': ')[1]
            elif line.startswith('- **æƒé‡**:') and current_doc:
                current_doc["weight"] = int(line.split(': ')[1])
            elif line.startswith('- **ç±»å‹**:') and current_doc:
                current_doc["type"] = line.split(': ')[1]
                current_doc["source"] = "index"

        # æœ€åä¸€ä¸ªæ–‡æ¡£
        if current_doc and any(kw in current_doc.get('keywords', '').lower() for kw in keywords):
            results.append(current_doc)

        return results

    def search_by_module(self, module: str) -> List[Dict]:
        """æ¨¡å¼ 3: æ¨¡å—åˆ†ç±»æœç´¢"""
        if not self.index_file.exists():
            return []

        # åœ¨ INDEX.md ä¸­æŸ¥æ‰¾å¯¹åº”æ¨¡å—çš„éƒ¨åˆ†
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æ›´ç²¾ç¡®

        return []

    def search_by_type(self, doc_type: str) -> List[Dict]:
        """æ¨¡å¼ 4: ç±»å‹æœç´¢"""
        if not self.index_file.exists():
            return []

        # åœ¨ INDEX.md ä¸­æŸ¥æ‰¾å¯¹åº”ç±»å‹çš„æ–‡æ¡£
        # ç®€åŒ–å®ç°

        return []

    def extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€åŒ–ç‰ˆå…³é”®è¯æå–
        keywords = re.findall(r'[\w\u4e00-\u9fff]+', query)
        return keywords[:10]

    def detect_module(self, query: str) -> str:
        """æ£€æµ‹æ¨¡å—"""
        query_lower = query.lower()

        if "å°çº¢ä¹¦" in query_lower or "å°é¢" in query_lower:
            return "xiaohongshu-cover"
        elif "è§†é¢‘" in query_lower:
            return "video-generator"
        elif "è®¤è¯" in query_lower or "auth" in query_lower:
            return "auth"
        elif "æµ‹è¯•" in query_lower:
            return "testing"
        else:
            return ""

    def detect_type(self, query: str) -> str:
        """æ£€æµ‹ç±»å‹"""
        query_lower = query.lower()

        if "bug" in query_lower or "é”™è¯¯" in query_lower or "å¤±è´¥" in query_lower:
            return "bug"
        elif "å¦‚ä½•" in query_lower or "æ€ä¹ˆ" in query_lower:
            return "guide"
        elif "æµ‹è¯•" in query_lower:
            return "test"
        else:
            return ""

    def deduplicate(self, results: List[Dict]) -> List[Dict]:
        """å»é‡"""
        seen = set()
        unique = []

        for result in results:
            # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºå”¯ä¸€æ ‡è¯†
            key = result.get("file", result.get("document", ""))
            if key and key not in seen:
                seen.add(key)
                unique.append(result)

        return unique

    def rank_results(self, results: List[Dict], query: str) -> List[Dict]:
        """æ’åºç»“æœ"""
        def calculate_score(result):
            score = 0

            # é—®é¢˜è®°å½•åŒ¹é…ä¼˜å…ˆ
            if result.get("type") == "exact_match":
                score += 50

            # æƒé‡
            weight = result.get("weight", 50)
            score += weight * 0.3

            # å…³é”®è¯åŒ¹é…åº¦
            keywords = self.extract_keywords(query)
            doc_keywords = result.get("keywords", "")
            matches = sum(1 for kw in keywords if kw.lower() in doc_keywords.lower())
            score += matches * 10

            return score

        return sorted(results, key=calculate_score, reverse=True)

    def check_quality(self, result: Dict) -> List[str]:
        """æ£€æŸ¥æ–‡æ¡£è´¨é‡"""
        warnings = []

        # æ—¶é—´æ£€æŸ¥
        if "last_updated" in result:
            last_updated = datetime.fromisoformat(result["last_updated"])
            age_days = (datetime.now() - last_updated).days

            if age_days > 365:
                warnings.append("âš ï¸ æ–‡æ¡£è¶…è¿‡1å¹´æœªæ›´æ–°ï¼Œå¯èƒ½å·²è¿‡æ—¶")
            elif age_days > 180:
                warnings.append("âš ï¸ æ–‡æ¡£è¶…è¿‡6ä¸ªæœˆæœªæ›´æ–°ï¼Œè¯·éªŒè¯")

        # è´¨é‡æ ‡è®°
        if result.get("quality") == "low":
            warnings.append("âš ï¸ æ–‡æ¡£è´¨é‡æ ‡è®°ä¸º lowï¼Œè°¨æ…ä½¿ç”¨")

        return warnings


def main():
    import argparse

    parser = argparse.ArgumentParser(description="æœç´¢é¡¹ç›®çŸ¥è¯†ç´¢å¼•")
    parser.add_argument("query", help="æœç´¢æŸ¥è¯¢")
    parser.add_argument("--project-root", default=".", help="é¡¹ç›®æ ¹ç›®å½•")

    args = parser.parse_args()

    searcher = IndexSearcher(args.project_root)
    results = searcher.search(args.query)

    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    if results["found"]:
        print(f"âœ… æ‰¾åˆ° {len(results['results'])} ä¸ªç»“æœ:\n")

        for i, result in enumerate(results["results"][:10], 1):
            print(f"{i}. {result.get('document', result.get('file', 'Unknown'))}")

            if result.get("type") == "exact_match":
                print(f"   ğŸ“ é—®é¢˜: {result.get('problem', '')}")
                print(f"   ğŸ“ å‡ºç°æ¬¡æ•°: {result.get('occurrence_count', 0)}")

            if "warnings" in result:
                for warning in result["warnings"]:
                    print(f"   {warning}")

            print()
    else:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
        print("ğŸ’¡ å»ºè®®:")
        print("  1. å°è¯•å…¶ä»–å…³é”®è¯")
        print("  2. è¿è¡Œ build_index.py é‡å»ºç´¢å¼•")
        print("  3. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨")


if __name__ == "__main__":
    main()
